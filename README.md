# ğŸš¢ Titanic Survival Prediction â€“ Neural Network

This project uses a neural network built with TensorFlow/Keras to predict passenger survival on the Titanic dataset. The goal is to explore classification techniques, data preprocessing, and model evaluation in a real-world scenario.

---

## ğŸ“Š Problem Statement

Given information about passengers such as age, gender, class, and fare, predict whether they survived the Titanic disaster or not.

- Type: Binary Classification (`Survived`: 0 = No, 1 = Yes)
- Dataset: [Titanic - Machine Learning from Disaster (Kaggle)](https://www.kaggle.com/c/titanic)

---

## ğŸ§  Model Summary

A simple feedforward neural network built using Keras with:

- Input Layer: Standardized numerical and encoded categorical features
- Hidden Layers: `Dense (64) â†’ Dropout â†’ Dense (32)`
- Output Layer: `Dense (1)` with `sigmoid` activation
- Loss Function: Binary Crossentropy
- Optimizer: Adam
- Accuracy achieved: **~80%**

---

## ğŸ› ï¸ Tech Stack

- **Language**: Python
- **Libraries**: Pandas, NumPy, Seaborn, Scikit-learn, TensorFlow/Keras, Matplotlib

---

## ğŸ“ Project Structure

titanic_survival/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ train.csv
â”œâ”€â”€ titanic.ipynb # Jupyter notebook with full code
â”œâ”€â”€ README.md # This file
â”œâ”€â”€ requirements.txt # Python packages

---

## ğŸ” Key Steps

1. **Data Preprocessing**
   - Handled missing values (`Age`, `Embarked`)
   - Removed irrelevant columns (`Name`, `Cabin`, `Ticket`)
   - Converted categorical variables with one-hot encoding

2. **Feature Scaling**
   - StandardScaler used to normalize inputs for neural network

3. **Model Building & Training**
   - Neural Network with Keras Sequential API
   - Dropout used to prevent overfitting
   - Trained for 50 epochs with validation split

4. **Evaluation**
   - Accuracy Score
   - Confusion Matrix
   - Classification Report

---

## ğŸ“ˆ Results

- **Test Accuracy**: ~80%
- Model shows good generalization and balance between precision & recall.

---

## ğŸ“Œ Future Improvements

- Hyperparameter tuning (batch size, epochs, layers)
- Try other models (Logistic Regression, Random Forest, XGBoost)
- Add cross-validation and AUC-ROC analysis
- Add test set predictions and submit to Kaggle

---

## ğŸ™Œ Author

**Adham Khalifa**  
ğŸ“« [LinkedIn](https://www.linkedin.com/in/abn-khalifa)  
ğŸ’» [GitHub](https://github.com/AbnKhalifa)

---

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).
